{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39db4ba6-051d-4091-9564-9f203f0df58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember !!!\n",
    "# First select the environment from Anaconda UI\n",
    "# Then open the Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb37482-e4a5-45b3-bf3c-08a05294265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\rankenv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# expected = 2.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409a1e12-9cfe-431f-b0d3-90ec767a328c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\rankenv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "0.5.5.dev\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_ranking as tfr\n",
    "print(tfr.__version__)\n",
    "# expected 0.5.5.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d82fd5-c32e-42fc-a5e8-1a9cf027416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93ba3bf-1fde-416c-be31-2c659bf4faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import our custom Dataloader\n",
    "from data_loader import DataLoader\n",
    "\n",
    "# Create an instance of DataLoader and pass the name of the dir that holds the dataset\n",
    "data_loader = DataLoader(data_dir=\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a86329-b058-4e29-a0c4-b7f01808c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load the CSV Data\n",
    "CSV_PATH = \"data/df_response_model_expression.csv\"\n",
    "\n",
    "def load_dataset():\n",
    "    column_names = ['DRUG_ID',\n",
    "                    'ARXSPAN_ID', \n",
    "                    'IC50_PUBLISHED', \n",
    "                    'OncotreeCode', \n",
    "                    'AgeCategory',\n",
    "                    'Sex',\n",
    "                    'ZMIZ1 (57178)', \n",
    "                    'ENG (2022)', \n",
    "                    'FGFR1 (2260)', \n",
    "                    'PAWR (5074)']\n",
    "\n",
    "    column_defaults = {\n",
    "        'DRUG_ID': tf.int32,\n",
    "        'ARXSPAN_ID': tf.string,\n",
    "        'IC50_PUBLISHED': tf.float32,\n",
    "        'OncotreeCode': tf.string,\n",
    "        'AgeCategory': tf.string,\n",
    "        'Sex': tf.string,\n",
    "        'ZMIZ1 (57178)': tf.float32,\n",
    "        'ENG (2022)': tf.float32,\n",
    "        'FGFR1 (2260)': tf.float32,\n",
    "        'PAWR (5074)': tf.float32\n",
    "    }\n",
    "    \n",
    "    # Load dataset from CSV file\n",
    "    csvdataset = tf.data.experimental.make_csv_dataset(\n",
    "        CSV_PATH,\n",
    "        batch_size = 8,\n",
    "        num_epochs = 1,  # Number of times to repeat the dataset\n",
    "        shuffle = False,  # Shuffle the data\n",
    "        column_names = column_names,  # Specify the column names\n",
    "        column_defaults=column_defaults, # Specify the column types\n",
    "        # label_name='IC50_PUBLISHED'  # Specify the target column\n",
    "    )\n",
    "\n",
    "    return csvdataset.unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "192a2909-3c90-4204-891b-d22c0fa2ab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n",
      "<_PrefetchDataset element_spec={'bucketized_user_age': TensorSpec(shape=(), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'movie_title': TensorSpec(shape=(), dtype=tf.string, name=None), 'raw_user_age': TensorSpec(shape=(), dtype=tf.float32, name=None), 'timestamp': TensorSpec(shape=(), dtype=tf.int64, name=None), 'user_gender': TensorSpec(shape=(), dtype=tf.bool, name=None), 'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_occupation_label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'user_occupation_text': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(), dtype=tf.float32, name=None), 'user_zip_code': TensorSpec(shape=(), dtype=tf.string, name=None)}>\n",
      "<class 'tensorflow.python.data.ops.unbatch_op._UnbatchDataset'>\n",
      "<_UnbatchDataset element_spec=OrderedDict([('DRUG_ID', TensorSpec(shape=(), dtype=tf.string, name=None)), ('ARXSPAN_ID', TensorSpec(shape=(), dtype=tf.string, name=None)), ('IC50_PUBLISHED', TensorSpec(shape=(), dtype=tf.string, name=None)), ('OncotreeCode', TensorSpec(shape=(), dtype=tf.string, name=None)), ('AgeCategory', TensorSpec(shape=(), dtype=tf.string, name=None)), ('Sex', TensorSpec(shape=(), dtype=tf.string, name=None)), ('ZMIZ1 (57178)', TensorSpec(shape=(), dtype=tf.string, name=None)), ('ENG (2022)', TensorSpec(shape=(), dtype=tf.string, name=None)), ('FGFR1 (2260)', TensorSpec(shape=(), dtype=tf.string, name=None)), ('PAWR (5074)', TensorSpec(shape=(), dtype=tf.string, name=None))])>\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
    "movies = tfds.load('movielens/100k-movies', split=\"train\")\n",
    "\n",
    "print(type(ratings))\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925a416-ed1c-4a21-9775-3f35b11f79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefetched = load_dataset()\n",
    "\n",
    "print(type(prefetched))\n",
    "print(prefetched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb0b02a-1d77-46c7-b417-bf42d2cdc631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MapDataset element_spec={'movie_title': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(), dtype=tf.float32, name=None)}>\n",
      "<_MapDataset element_spec={'DRUG_ID': TensorSpec(shape=(), dtype=tf.string, name=None), 'ARXSPAN_ID': TensorSpec(shape=(), dtype=tf.string, name=None), 'IC50_PUBLISHED': TensorSpec(shape=(), dtype=tf.float32, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select the basic features.\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"]\n",
    "})\n",
    "print(ratings)\n",
    "\n",
    "prefetched = prefetched.map(lambda x: {\n",
    "    \"DRUG_ID\": x[\"DRUG_ID\"],\n",
    "    \"ARXSPAN_ID\": x[\"ARXSPAN_ID\"],\n",
    "    \"IC50_PUBLISHED\": tf.strings.to_number(x[\"IC50_PUBLISHED\"], tf.float32)\n",
    "})\n",
    "print(prefetched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d867f5-74bb-44c7-af28-7df0dc95d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\rankenv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\rankenv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\rankenv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\rankenv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build vocabularies to convert all user ids and all movie titles into integer indices for embedding layers/:\n",
    "\n",
    "users = ratings.map(lambda x: x[\"user_id\"])\n",
    "user_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(users.batch(1000))\n",
    "\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])\n",
    "movie_titles_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
    "movie_titles_vocabulary.adapt(movies.batch(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f51fbb8-7cdd-4ade-be9f-c498a3962990",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_lines = prefetched.map(lambda x: x[\"ARXSPAN_ID\"])\n",
    "cell_line_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
    "cell_line_ids_vocabulary.adapt(cell_lines.batch(1000))\n",
    "\n",
    "drugs = prefetched.map(lambda x: x[\"DRUG_ID\"])\n",
    "drug_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
    "drug_ids_vocabulary.adapt(drugs.batch(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0abfb5-4dc1-42f7-8946-3765097b0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by user_id\n",
    "key_func = lambda x: user_ids_vocabulary(x[\"user_id\"])\n",
    "reduce_func = lambda key, dataset: dataset.batch(100)\n",
    "ds_train = ratings.group_by_window(key_func=key_func, reduce_func=reduce_func, window_size=100)\n",
    "\n",
    "# Group by ARXSPAN_ID\n",
    "my_key_func = lambda x: cell_line_ids_vocabulary(x[\"ARXSPAN_ID\"])\n",
    "my_reduce_func = lambda key, dataset: dataset.batch(100)\n",
    "my_ds_train = prefetched.group_by_window(key_func=my_key_func, reduce_func=my_reduce_func, window_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba31445-1b27-4d50-a8a8-55ece1501c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of movie_title: (100,)\n",
      "Example values of movie_title: [b'Man Who Would Be King, The (1975)' b'Silence of the Lambs, The (1991)'\n",
      " b'Next Karate Kid, The (1994)' b'2001: A Space Odyssey (1968)'\n",
      " b'Usual Suspects, The (1995)']\n",
      "\n",
      "Shape of user_id: (100,)\n",
      "Example values of user_id: [b'405' b'405' b'405' b'405' b'405']\n",
      "\n",
      "Shape of user_rating: (100,)\n",
      "Example values of user_rating: [1. 4. 1. 5. 5.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ds_train.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:5].numpy()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28c0428f-6f39-4646-9aa1-95f0cb51687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DRUG_ID: (100,)\n",
      "Example values of DRUG_ID: [b'1003' b'1004' b'1005' b'1006' b'1007']\n",
      "\n",
      "Shape of ARXSPAN_ID: (100,)\n",
      "Example values of ARXSPAN_ID: [b'ACH-000910' b'ACH-000910' b'ACH-000910' b'ACH-000910' b'ACH-000910']\n",
      "\n",
      "Shape of IC50_PUBLISHED: (100,)\n",
      "Example values of IC50_PUBLISHED: [1.4789245e-01 2.4882589e-02 8.6001694e+01 4.5610552e+00 8.6790435e-03]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in my_ds_train.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:5].numpy()}\")\n",
    "    print()\n",
    "\n",
    "# !!! At this point investigate if indeed we have records of the ACH-000910 being treated with these drugs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4df3ab5a-d732-4fff-b1f8-789978380536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_12352\\478111760.py:12: dense_to_ragged_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ragged_batch` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_12352\\478111760.py:12: dense_to_ragged_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ragged_batch` instead.\n"
     ]
    }
   ],
   "source": [
    "# Generate batched features and labels\n",
    "\n",
    "def _features_and_labels(x: Dict[str, tf.Tensor]) -> Tuple[Dict[str, tf.Tensor], tf.Tensor]:\n",
    "  labels = x.pop(\"user_rating\")\n",
    "  return x, labels\n",
    "\n",
    "def _my_features_and_labels(x: Dict[str, tf.Tensor]) -> Tuple[Dict[str, tf.Tensor], tf.Tensor]:\n",
    "  labels = x.pop(\"IC50_PUBLISHED\")\n",
    "  return x, labels\n",
    "\n",
    "ds_train = ds_train.map(_features_and_labels)\n",
    "ds_train = ds_train.apply(tf.data.experimental.dense_to_ragged_batch(batch_size=32))\n",
    "\n",
    "my_ds_train = my_ds_train.map(_my_features_and_labels)\n",
    "my_ds_train = my_ds_train.apply(tf.data.experimental.dense_to_ragged_batch(batch_size=32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6f7a4c7-f430-4da5-b9c2-826f775bf39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of movie_title: (32, None)\n",
      "Example values of movie_title: [[b'Man Who Would Be King, The (1975)'\n",
      "  b'Silence of the Lambs, The (1991)' b'Next Karate Kid, The (1994)']\n",
      " [b'Flower of My Secret, The (Flor de mi secreto, La) (1995)'\n",
      "  b'Little Princess, The (1939)' b'Time to Kill, A (1996)']\n",
      " [b'Kundun (1997)' b'Scream (1996)' b'Power 98 (1995)']]\n",
      "\n",
      "Shape of user_id: (32, None)\n",
      "Example values of user_id: [[b'405' b'405' b'405']\n",
      " [b'655' b'655' b'655']\n",
      " [b'13' b'13' b'13']]\n",
      "\n",
      "Shape of label: (32, None)\n",
      "Example values of label: [[1. 4. 1.]\n",
      " [3. 3. 3.]\n",
      " [5. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "for x, label in ds_train.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:3, :3].numpy()}\")\n",
    "    print()\n",
    "  print(f\"Shape of label: {label.shape}\")\n",
    "  print(f\"Example values of label: {label[:3, :3].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "031db6cb-4e7f-4ebb-b685-1ac035152702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DRUG_ID: (32, None)\n",
      "Example values of DRUG_ID: [[b'1003' b'1004' b'1005']\n",
      " [b'1003' b'1004' b'1005']\n",
      " [b'1003' b'1004' b'1005']]\n",
      "\n",
      "Shape of ARXSPAN_ID: (32, None)\n",
      "Example values of ARXSPAN_ID: [[b'ACH-000910' b'ACH-000910' b'ACH-000910']\n",
      " [b'ACH-000876' b'ACH-000876' b'ACH-000876']\n",
      " [b'ACH-000783' b'ACH-000783' b'ACH-000783']]\n",
      "\n",
      "Shape of label: (32, None)\n",
      "Example values of label: [[1.4789245e-01 2.4882589e-02 8.6001694e+01]\n",
      " [1.1501115e+01 2.6155075e-02 8.4742218e+02]\n",
      " [1.9450953e+00 1.7586000e-01 2.0785484e+02]]\n"
     ]
    }
   ],
   "source": [
    "for x, label in my_ds_train.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:3, :3].numpy()}\")\n",
    "    print()\n",
    "  print(f\"Shape of label: {label.shape}\")\n",
    "  print(f\"Example values of label: {label[:3, :3].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16026648-2819-481a-9573-e12150ca8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "class MovieLensRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, user_vocab, movie_vocab):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie vocabulary and embedding.\n",
    "    self.user_vocab = user_vocab\n",
    "    self.movie_vocab = movie_vocab\n",
    "    self.user_embed = tf.keras.layers.Embedding(user_vocab.vocabulary_size(), 64)\n",
    "    self.movie_embed = tf.keras.layers.Embedding(movie_vocab.vocabulary_size(), 64)\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    # Define how the ranking scores are computed: \n",
    "    # Take the dot-product of the user embeddings with the movie embeddings.\n",
    "\n",
    "    user_embeddings = self.user_embed(self.user_vocab(features[\"user_id\"]))\n",
    "    movie_embeddings = self.movie_embed(\n",
    "        self.movie_vocab(features[\"movie_title\"]))\n",
    "\n",
    "    return tf.reduce_sum(user_embeddings * movie_embeddings, axis=2)\n",
    "\n",
    "# Define a model\n",
    "class DrugRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, user_vocab, movie_vocab):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie vocabulary and embedding.\n",
    "    self.user_vocab = user_vocab\n",
    "    self.movie_vocab = movie_vocab\n",
    "    self.user_embed = tf.keras.layers.Embedding(user_vocab.vocabulary_size(),64)\n",
    "    self.movie_embed = tf.keras.layers.Embedding(movie_vocab.vocabulary_size(),64)\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    # Define how the ranking scores are computed: \n",
    "    # Take the dot-product of the user embeddings with the movie embeddings.\n",
    "\n",
    "    user_embeddings = self.user_embed(self.user_vocab(features[\"ARXSPAN_ID\"]))\n",
    "    movie_embeddings = self.movie_embed(self.movie_vocab(features[\"DRUG_ID\"]))\n",
    "\n",
    "    return tf.reduce_sum(user_embeddings * movie_embeddings, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52688a2f-17ce-40bf-a810-e8f3fef82454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ranking model, trained with a ranking loss and evaluated with\n",
    "# ranking metrics.\n",
    "model = MovieLensRankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
    "optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "loss = tfr.keras.losses.get(\n",
    "    loss=tfr.keras.losses.RankingLossKey.SOFTMAX_LOSS, ragged=True)\n",
    "eval_metrics = [\n",
    "    tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "    tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73fa2701-efd6-4bcb-a5cc-acf9bed256b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ranking model, trained with a ranking loss and evaluated with\n",
    "# ranking metrics.\n",
    "my_model = DrugRankingModel(cell_line_ids_vocabulary, drug_ids_vocabulary)\n",
    "my_optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "my_loss = tfr.keras.losses.get(loss=tfr.keras.losses.RankingLossKey.SOFTMAX_LOSS, ragged=True)\n",
    "my_eval_metrics = [\n",
    "    tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "    tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "]\n",
    "my_model.compile(optimizer=my_optimizer, loss=my_loss, metrics=my_eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8119f5a-a493-446e-a955-8103a944a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\rankenv\\lib\\site-packages\\tensorflow_ranking\\python\\losses_impl.py:497: The name tf.where is deprecated. Please use tf.compat.v1.where instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\rankenv\\lib\\site-packages\\tensorflow_ranking\\python\\losses_impl.py:497: The name tf.where is deprecated. Please use tf.compat.v1.where instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 7s 52ms/step - loss: 998.7459 - metric/ndcg: 0.8284 - metric/mrr: 1.0000\n",
      "Epoch 2/3\n",
      "48/48 [==============================] - 3s 47ms/step - loss: 997.0272 - metric/ndcg: 0.9179 - metric/mrr: 1.0000\n",
      "Epoch 3/3\n",
      "48/48 [==============================] - 3s 46ms/step - loss: 994.8143 - metric/ndcg: 0.9396 - metric/mrr: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b1e7558d30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f53872f4-38bd-496f-b80e-8b68e1ca36b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=({'movie_title': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int64), 'user_id': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int64)}, RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int64))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3c54862-6410-4951-85f8-fa6d84ae9c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "36/36 [==============================] - 5s 41ms/step - loss: 79452.1328 - metric/ndcg: nan - metric/mrr: 0.9775\n",
      "Epoch 2/3\n",
      "36/36 [==============================] - 3s 43ms/step - loss: 109328.3672 - metric/ndcg: nan - metric/mrr: 0.9904\n",
      "Epoch 3/3\n",
      "36/36 [==============================] - 3s 40ms/step - loss: 86940.0000 - metric/ndcg: nan - metric/mrr: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b1e75a5cc0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(my_ds_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45f5e6c2-05a9-4f4c-a886-a504cd7762f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 42: [b'Star Wars (1977)' b'Empire Strikes Back, The (1980)' b'Titanic (1997)'\n",
      " b'Raiders of the Lost Ark (1981)' b'Return of the Jedi (1983)']\n"
     ]
    }
   ],
   "source": [
    "# Get movie title candidate list.\n",
    "for movie_titles in movies.batch(2000):\n",
    "  break\n",
    "\n",
    "# Generate the input for user 42.\n",
    "inputs = {\n",
    "    \"user_id\":\n",
    "        tf.expand_dims(tf.repeat(\"42\", repeats=movie_titles.shape[0]), axis=0),\n",
    "    \"movie_title\":\n",
    "        tf.expand_dims(movie_titles, axis=0)\n",
    "}\n",
    "\n",
    "# Get movie recommendations for user 42.\n",
    "scores = model(inputs)\n",
    "titles = tfr.utils.sort_by_scores(scores,\n",
    "                                  [tf.expand_dims(movie_titles, axis=0)])[0]\n",
    "print(f\"Top 5 recommendations for user 42: {titles[0, :5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd51303f-7236-40fb-b8fa-e1f65585cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 drug recommendations for user ACH-000876: [b'1005' b'1005' b'1005' ... b'1004' b'1004' b'1004']\n"
     ]
    }
   ],
   "source": [
    "# Get movie title candidate list.\n",
    "for drug in drugs.batch(2000):\n",
    "  break\n",
    "\n",
    "# Generate the input for user 42.\n",
    "my_inputs = {\n",
    "    \"ARXSPAN_ID\":\n",
    "        tf.expand_dims(tf.repeat(\"ACH-000876\", repeats=drug.shape[0]), axis=0),\n",
    "    \"DRUG_ID\":\n",
    "        tf.expand_dims(drug, axis=0)\n",
    "}\n",
    "\n",
    "# Get drug recommendations for user ACH-000876.\n",
    "my_scores = my_model(my_inputs)\n",
    "proposed_drugs = tfr.utils.sort_by_scores(my_scores,\n",
    "                                  [tf.expand_dims(drug, axis=0)])[0]\n",
    "print(f\"Top 5 drug recommendations for user ACH-000876: {proposed_drugs[0, :]}\")\n",
    "\n",
    "# !!! To investigate:\n",
    "# 1) Lower IC50 is better so maybe we should somehow pass this info to the model, maybe by inversing the values or with another way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
